{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, GRU, Embedding, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # obtains tokens with a least 1 alphabet\n",
    "    pattern = re.compile(r'[A-Za-z]+[\\w^\\']*|[\\w^\\']*[A-Za-z]+[\\w^\\']*')\n",
    "    return pattern.findall(text.lower())\n",
    "def mapping(tokens):\n",
    "    word_to_id = dict()\n",
    "    id_to_word = dict()\n",
    "    for i,word in enumerate(set(tokens)):\n",
    "        word_to_id[word] = i\n",
    "        id_to_word[i] = word\n",
    "    return word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['after', 'the', 'deduction', 'of', 'the', 'costs', 'of', 'investing', 'beating', 'the', 'stock', 'market', 'is', 'a', \"loser's\", 'game']\n"
     ]
    }
   ],
   "source": [
    "doc = \"After the deduction of the costs of investing, \" \\\n",
    "      \"beating the stock market is a loser's game.\"\n",
    "tokens = tokenize(doc)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 0, 'after': 1, 'market': 2, 'game': 3, 'beating': 4, 'a': 5, 'is': 6, 'costs': 7, 'stock': 8, 'investing': 9, \"loser's\": 10, 'deduction': 11, 'of': 12}\n",
      "{0: 'the', 1: 'after', 2: 'market', 3: 'game', 4: 'beating', 5: 'a', 6: 'is', 7: 'costs', 8: 'stock', 9: 'investing', 10: \"loser's\", 11: 'deduction', 12: 'of'}\n"
     ]
    }
   ],
   "source": [
    "word_to_id, id_to_word = mapping(tokens)\n",
    "print(word_to_id)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real code\n",
    "def generate_training_data(tokens, word_to_id, window_size):\n",
    "    L = len(tokens)\n",
    "    X, Y = [], []\n",
    "    tempX, tempY = [], []\n",
    "    for i in range(L):\n",
    "        index_before_after = list(range(max(0, i - window_size), i)) + \\\n",
    "                             list(range(i + 1, min(i + window_size + 1,L)))\n",
    "        #print(index_before_after)\n",
    "        for j in index_before_after:\n",
    "            tempX.append(word_to_id[tokens[j]])\n",
    "            #tempY.append(word_to_id[tokens[i]])\n",
    "        print(tempX)\n",
    "        X.append(tempX)\n",
    "        Y.append(word_to_id[tokens[i]])\n",
    "        tempX = []\n",
    "    #X = np.array(X)\n",
    "    #Y = np.array(Y)    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 11, 12]\n",
      "[1, 11, 12, 0]\n",
      "[1, 0, 12, 0, 7]\n",
      "[1, 0, 11, 0, 7, 12]\n",
      "[0, 11, 12, 7, 12, 9]\n",
      "[11, 12, 0, 12, 9, 4]\n",
      "[12, 0, 7, 9, 4, 0]\n",
      "[0, 7, 12, 4, 0, 8]\n",
      "[7, 12, 9, 0, 8, 2]\n",
      "[12, 9, 4, 8, 2, 6]\n",
      "[9, 4, 0, 2, 6, 5]\n",
      "[4, 0, 8, 6, 5, 10]\n",
      "[0, 8, 2, 5, 10, 3]\n",
      "[8, 2, 6, 10, 3]\n",
      "[2, 6, 5, 3]\n",
      "[6, 5, 10]\n",
      "[[0, 11, 12], [1, 11, 12, 0], [1, 0, 12, 0, 7], [1, 0, 11, 0, 7, 12], [0, 11, 12, 7, 12, 9], [11, 12, 0, 12, 9, 4], [12, 0, 7, 9, 4, 0], [0, 7, 12, 4, 0, 8], [7, 12, 9, 0, 8, 2], [12, 9, 4, 8, 2, 6]]\n",
      "<class 'list'>\n",
      "------------------------------------------------------\n",
      "[1, 0, 11, 12, 0, 7, 12, 9, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "X,Y = generate_training_data(tokens, word_to_id, 3)\n",
    "print(X[:10])\n",
    "print(type(X))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(Y[:10])\n",
    "#print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 11 12  0  0  0]\n",
      " [ 1 11 12  0  0  0]\n",
      " [ 1  0 12  0  7  0]\n",
      " [ 1  0 11  0  7 12]\n",
      " [ 0 11 12  7 12  9]\n",
      " [11 12  0 12  9  4]\n",
      " [12  0  7  9  4  0]\n",
      " [ 0  7 12  4  0  8]\n",
      " [ 7 12  9  0  8  2]\n",
      " [12  9  4  8  2  6]\n",
      " [ 9  4  0  2  6  5]\n",
      " [ 4  0  8  6  5 10]\n",
      " [ 0  8  2  5 10  3]\n",
      " [ 8  2  6 10  3  0]\n",
      " [ 2  6  5  3  0  0]\n",
      " [ 6  5 10  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 6\n",
    "\n",
    "X = pad_sequences(X, maxlen=MAX_LENGTH, padding='post')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 13)\n"
     ]
    }
   ],
   "source": [
    "Y = to_categorical(Y, num_classes=13)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hieu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 6, 50)             650       \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 150)               90450     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                1963      \n",
      "=================================================================\n",
      "Total params: 93,063\n",
      "Trainable params: 93,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(13, 50, input_length=6))\n",
    "model.add(GRU(150, recurrent_dropout=0.1, dropout=0.1))\n",
    "model.add(Dense(13, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hieu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 0s - loss: 2.5657 - acc: 0.0625\n",
      "Epoch 2/100\n",
      " - 0s - loss: 2.5577 - acc: 0.1875\n",
      "Epoch 3/100\n",
      " - 0s - loss: 2.5510 - acc: 0.1875\n",
      "Epoch 4/100\n",
      " - 0s - loss: 2.5429 - acc: 0.1875\n",
      "Epoch 5/100\n",
      " - 0s - loss: 2.5340 - acc: 0.2500\n",
      "Epoch 6/100\n",
      " - 0s - loss: 2.5258 - acc: 0.2500\n",
      "Epoch 7/100\n",
      " - 0s - loss: 2.5209 - acc: 0.1875\n",
      "Epoch 8/100\n",
      " - 0s - loss: 2.5135 - acc: 0.1875\n",
      "Epoch 9/100\n",
      " - 0s - loss: 2.5004 - acc: 0.1875\n",
      "Epoch 10/100\n",
      " - 0s - loss: 2.4937 - acc: 0.1875\n",
      "Epoch 11/100\n",
      " - 0s - loss: 2.4839 - acc: 0.1875\n",
      "Epoch 12/100\n",
      " - 0s - loss: 2.4708 - acc: 0.1875\n",
      "Epoch 13/100\n",
      " - 0s - loss: 2.4537 - acc: 0.1875\n",
      "Epoch 14/100\n",
      " - 0s - loss: 2.4413 - acc: 0.1875\n",
      "Epoch 15/100\n",
      " - 0s - loss: 2.4285 - acc: 0.1875\n",
      "Epoch 16/100\n",
      " - 0s - loss: 2.4153 - acc: 0.1875\n",
      "Epoch 17/100\n",
      " - 0s - loss: 2.4074 - acc: 0.1875\n",
      "Epoch 18/100\n",
      " - 0s - loss: 2.3768 - acc: 0.1875\n",
      "Epoch 19/100\n",
      " - 0s - loss: 2.3492 - acc: 0.1875\n",
      "Epoch 20/100\n",
      " - 0s - loss: 2.3470 - acc: 0.1875\n",
      "Epoch 21/100\n",
      " - 0s - loss: 2.3161 - acc: 0.1875\n",
      "Epoch 22/100\n",
      " - 0s - loss: 2.2994 - acc: 0.1875\n",
      "Epoch 23/100\n",
      " - 0s - loss: 2.2774 - acc: 0.1875\n",
      "Epoch 24/100\n",
      " - 0s - loss: 2.2461 - acc: 0.1875\n",
      "Epoch 25/100\n",
      " - 0s - loss: 2.2386 - acc: 0.1875\n",
      "Epoch 26/100\n",
      " - 0s - loss: 2.2390 - acc: 0.1875\n",
      "Epoch 27/100\n",
      " - 0s - loss: 2.1684 - acc: 0.1875\n",
      "Epoch 28/100\n",
      " - 0s - loss: 2.1784 - acc: 0.1875\n",
      "Epoch 29/100\n",
      " - 0s - loss: 2.1273 - acc: 0.1875\n",
      "Epoch 30/100\n",
      " - 0s - loss: 2.1133 - acc: 0.2500\n",
      "Epoch 31/100\n",
      " - 0s - loss: 2.0762 - acc: 0.2500\n",
      "Epoch 32/100\n",
      " - 0s - loss: 2.0483 - acc: 0.3750\n",
      "Epoch 33/100\n",
      " - 0s - loss: 1.9863 - acc: 0.3750\n",
      "Epoch 34/100\n",
      " - 0s - loss: 1.9730 - acc: 0.3750\n",
      "Epoch 35/100\n",
      " - 0s - loss: 1.9258 - acc: 0.4375\n",
      "Epoch 36/100\n",
      " - 0s - loss: 1.8717 - acc: 0.5000\n",
      "Epoch 37/100\n",
      " - 0s - loss: 1.8120 - acc: 0.4375\n",
      "Epoch 38/100\n",
      " - 0s - loss: 1.7905 - acc: 0.4375\n",
      "Epoch 39/100\n",
      " - 0s - loss: 1.7240 - acc: 0.5000\n",
      "Epoch 40/100\n",
      " - 0s - loss: 1.6674 - acc: 0.4375\n",
      "Epoch 41/100\n",
      " - 0s - loss: 1.6098 - acc: 0.4375\n",
      "Epoch 42/100\n",
      " - 0s - loss: 1.5662 - acc: 0.4375\n",
      "Epoch 43/100\n",
      " - 0s - loss: 1.5842 - acc: 0.4375\n",
      "Epoch 44/100\n",
      " - 0s - loss: 1.4667 - acc: 0.5000\n",
      "Epoch 45/100\n",
      " - 0s - loss: 1.4295 - acc: 0.5000\n",
      "Epoch 46/100\n",
      " - 0s - loss: 1.3976 - acc: 0.5000\n",
      "Epoch 47/100\n",
      " - 0s - loss: 1.4058 - acc: 0.5000\n",
      "Epoch 48/100\n",
      " - 0s - loss: 1.3653 - acc: 0.5625\n",
      "Epoch 49/100\n",
      " - 0s - loss: 1.2946 - acc: 0.6875\n",
      "Epoch 50/100\n",
      " - 0s - loss: 1.3070 - acc: 0.5625\n",
      "Epoch 51/100\n",
      " - 0s - loss: 1.2782 - acc: 0.6250\n",
      "Epoch 52/100\n",
      " - 0s - loss: 1.1564 - acc: 0.5625\n",
      "Epoch 53/100\n",
      " - 0s - loss: 1.1465 - acc: 0.6250\n",
      "Epoch 54/100\n",
      " - 0s - loss: 1.1117 - acc: 0.5625\n",
      "Epoch 55/100\n",
      " - 0s - loss: 1.1171 - acc: 0.5625\n",
      "Epoch 56/100\n",
      " - 0s - loss: 1.0746 - acc: 0.6250\n",
      "Epoch 57/100\n",
      " - 0s - loss: 1.0499 - acc: 0.6250\n",
      "Epoch 58/100\n",
      " - 0s - loss: 1.0196 - acc: 0.6250\n",
      "Epoch 59/100\n",
      " - 0s - loss: 1.0313 - acc: 0.6250\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.8980 - acc: 0.7500\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.9019 - acc: 0.8750\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.9255 - acc: 0.8125\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.8625 - acc: 0.8125\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.8244 - acc: 0.8125\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.8556 - acc: 0.7500\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.7716 - acc: 0.8125\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.7528 - acc: 0.8750\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.6423 - acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.6420 - acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.6731 - acc: 0.9375\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.6088 - acc: 0.9375\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.5799 - acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.6280 - acc: 0.8750\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.5333 - acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4936 - acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.5126 - acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.4796 - acc: 0.9375\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4671 - acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4894 - acc: 0.9375\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4830 - acc: 0.8125\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4135 - acc: 0.9375\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.3752 - acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4167 - acc: 0.9375\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.3232 - acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.3630 - acc: 0.9375\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.3118 - acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.2962 - acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.3585 - acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.3002 - acc: 0.9375\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.3010 - acc: 0.9375\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.2384 - acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.2397 - acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.2680 - acc: 0.9375\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.2431 - acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.2062 - acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.1891 - acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.1835 - acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.1918 - acc: 0.9375\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.1725 - acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.1716 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f69253ab490>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X, Y, epochs=100, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0\n",
      "8\n",
      "6\n",
      "5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(word_to_id['beating'])\n",
    "print(word_to_id['the'])\n",
    "print(word_to_id['stock'])\n",
    "print(word_to_id['is'])\n",
    "print(word_to_id['a'])\n",
    "print(word_to_id[\"loser's\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n"
     ]
    }
   ],
   "source": [
    "temp = np.array([[ 4,0,8,6,5,10]])\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.6379066e-04 1.0716057e-06 8.5258102e-01 1.3444260e-05 1.2245412e-03\n",
      "  2.3611935e-02 2.6541259e-02 2.9621115e-05 9.4571628e-02 3.1810878e-06\n",
      "  1.1495572e-03 2.9548980e-06 5.9930489e-06]]\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict_proba(temp, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict_classes(temp, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "market\n"
     ]
    }
   ],
   "source": [
    "print(id_to_word[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
